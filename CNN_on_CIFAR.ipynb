{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "num_epochs = 4\n",
    "learning_rate = 0.001\n",
    "batchsize = 10\n",
    "\n",
    "\n",
    "# define a transform remember how we commented it out in Feed_forward_NN\n",
    "\n",
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])  # transformations are applied in the order they are listed in the transform.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this transform do ?\n",
    "\n",
    "toTensor : This transformation converts a PIL Image or a NumPy ndarray into a PyTorch tensor.\n",
    "For images, it changes the shape from (H, W, C) (Height, Width, Channels) to (C, H, W) and scales the pixel values from the range [0, 255] to [0, 1].\n",
    "\n",
    "Normalize : This transformation normalizes the tensor image with mean and standard deviation. The mean and standard deviation are provided for each channel (RGB) respectively.\n",
    "Mean: (0.5, 0.5, 0.5) for the R, G, B channels.\n",
    "Standard Deviation: (0.5, 0.5, 0.5) for the R, G, B channels.\n",
    "The normalization is performed using the formula:\n",
    "\n",
    "normalized_pixel = (pixelâˆ’mean)/std \n",
    "\n",
    "Given the mean and standard deviation of 0.5, this normalization maps the pixel values from [0, 1] to [-1, 1].\n",
    "\n",
    "why ? \n",
    "\n",
    "lower bound = 0-0.5(mean)/0.5(std) = -1 \n",
    "upper bound = 1-0.5/0.5 = 1 \n",
    "\n",
    "what does transformation achieve ? \n",
    "\n",
    "This preprocessing step is crucial for training neural networks, as it ensures that the input data is in a consistent format and within a range that is suitable for the network's activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# prepare datasets \n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root = './data/CIFAR',\n",
    "    train=True,\n",
    "    transform=tf,\n",
    "    download=True\n",
    "    )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/CIFAR',\n",
    "    train = False,\n",
    "    transform=tf,\n",
    "    download=True\n",
    "    )\n",
    "\n",
    "# prepare dataloaders\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a convolutional model\n",
    "# model set up main remember initialisation and forward.\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,3)    # input channels, output channels, kernel size.\n",
    "        self.pool = nn.MaxPool2d(2,2)   # kernel size, stride - we move 2 to the right remember the diagram?\n",
    "        self.conv2 = nn.Conv2d(6,16,4)\n",
    "        self.fc1 = nn.Linear(16*6*6,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1,16*6*6)            # x.view different from reshape as it returns a new tensor without changes to old one.\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = (self.fc3(x))       # no activation or softmax cause it is directly applied/evaluated by the loss fucntion\n",
    "        return x\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "               \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula to calculate ouputs from convulation :-\n",
    "\n",
    "((Input-Filtersize+2*padding)/Stride) + 1\n",
    "\n",
    "here \n",
    "input = 32\n",
    "filter = 3\n",
    "padding = 0\n",
    "stride = 1\n",
    "final size = 32-3+1 = 30*30\n",
    "\n",
    "after 2,2 pooling each 2*2 square gets converted to 1 square = max of all 4.\n",
    "\n",
    "after pooling = 15*15  : no of blocks decrease by /4.\n",
    "\n",
    "after another conv with kernel size 4\n",
    "\n",
    "15-4+1 = 12\n",
    "\n",
    "another max pool -> final size = 6*6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise our model\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# again what do we define after this?\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer  = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1/4, step = 1/5000, loss =  2.30\n",
      "epoch = 1/4, step = 101/5000, loss =  2.31\n",
      "epoch = 1/4, step = 201/5000, loss =  2.30\n",
      "epoch = 1/4, step = 301/5000, loss =  2.30\n",
      "epoch = 1/4, step = 401/5000, loss =  2.29\n",
      "epoch = 1/4, step = 501/5000, loss =  2.30\n",
      "epoch = 1/4, step = 601/5000, loss =  2.29\n",
      "epoch = 1/4, step = 701/5000, loss =  2.30\n",
      "epoch = 1/4, step = 801/5000, loss =  2.29\n",
      "epoch = 1/4, step = 901/5000, loss =  2.31\n",
      "epoch = 1/4, step = 1001/5000, loss =  2.29\n",
      "epoch = 1/4, step = 1101/5000, loss =  2.30\n",
      "epoch = 1/4, step = 1201/5000, loss =  2.29\n",
      "epoch = 1/4, step = 1301/5000, loss =  2.31\n",
      "epoch = 1/4, step = 1401/5000, loss =  2.29\n",
      "epoch = 1/4, step = 1501/5000, loss =  2.29\n",
      "epoch = 1/4, step = 1601/5000, loss =  2.30\n",
      "epoch = 1/4, step = 1701/5000, loss =  2.31\n",
      "epoch = 1/4, step = 1801/5000, loss =  2.29\n",
      "epoch = 1/4, step = 1901/5000, loss =  2.30\n",
      "epoch = 1/4, step = 2001/5000, loss =  2.30\n",
      "epoch = 1/4, step = 2101/5000, loss =  2.32\n",
      "epoch = 1/4, step = 2201/5000, loss =  2.30\n",
      "epoch = 1/4, step = 2301/5000, loss =  2.31\n",
      "epoch = 1/4, step = 2401/5000, loss =  2.29\n",
      "epoch = 1/4, step = 2501/5000, loss =  2.29\n",
      "epoch = 1/4, step = 2601/5000, loss =  2.30\n",
      "epoch = 1/4, step = 2701/5000, loss =  2.30\n",
      "epoch = 1/4, step = 2801/5000, loss =  2.31\n",
      "epoch = 1/4, step = 2901/5000, loss =  2.28\n",
      "epoch = 1/4, step = 3001/5000, loss =  2.30\n",
      "epoch = 1/4, step = 3101/5000, loss =  2.29\n",
      "epoch = 1/4, step = 3201/5000, loss =  2.29\n",
      "epoch = 1/4, step = 3301/5000, loss =  2.30\n",
      "epoch = 1/4, step = 3401/5000, loss =  2.29\n",
      "epoch = 1/4, step = 3501/5000, loss =  2.29\n",
      "epoch = 1/4, step = 3601/5000, loss =  2.30\n",
      "epoch = 1/4, step = 3701/5000, loss =  2.29\n",
      "epoch = 1/4, step = 3801/5000, loss =  2.30\n",
      "epoch = 1/4, step = 3901/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4001/5000, loss =  2.31\n",
      "epoch = 1/4, step = 4101/5000, loss =  2.31\n",
      "epoch = 1/4, step = 4201/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4301/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4401/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4501/5000, loss =  2.28\n",
      "epoch = 1/4, step = 4601/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4701/5000, loss =  2.30\n",
      "epoch = 1/4, step = 4801/5000, loss =  2.29\n",
      "epoch = 1/4, step = 4901/5000, loss =  2.30\n",
      "epoch = 2/4, step = 1/5000, loss =  2.30\n",
      "epoch = 2/4, step = 101/5000, loss =  2.30\n",
      "epoch = 2/4, step = 201/5000, loss =  2.30\n",
      "epoch = 2/4, step = 301/5000, loss =  2.29\n",
      "epoch = 2/4, step = 401/5000, loss =  2.30\n",
      "epoch = 2/4, step = 501/5000, loss =  2.32\n",
      "epoch = 2/4, step = 601/5000, loss =  2.28\n",
      "epoch = 2/4, step = 701/5000, loss =  2.27\n",
      "epoch = 2/4, step = 801/5000, loss =  2.30\n",
      "epoch = 2/4, step = 901/5000, loss =  2.28\n",
      "epoch = 2/4, step = 1001/5000, loss =  2.33\n",
      "epoch = 2/4, step = 1101/5000, loss =  2.27\n",
      "epoch = 2/4, step = 1201/5000, loss =  2.28\n",
      "epoch = 2/4, step = 1301/5000, loss =  2.31\n",
      "epoch = 2/4, step = 1401/5000, loss =  2.27\n",
      "epoch = 2/4, step = 1501/5000, loss =  2.30\n",
      "epoch = 2/4, step = 1601/5000, loss =  2.25\n",
      "epoch = 2/4, step = 1701/5000, loss =  2.29\n",
      "epoch = 2/4, step = 1801/5000, loss =  2.31\n",
      "epoch = 2/4, step = 1901/5000, loss =  2.27\n",
      "epoch = 2/4, step = 2001/5000, loss =  2.26\n",
      "epoch = 2/4, step = 2101/5000, loss =  2.23\n",
      "epoch = 2/4, step = 2201/5000, loss =  2.26\n",
      "epoch = 2/4, step = 2301/5000, loss =  2.25\n",
      "epoch = 2/4, step = 2401/5000, loss =  2.27\n",
      "epoch = 2/4, step = 2501/5000, loss =  2.24\n",
      "epoch = 2/4, step = 2601/5000, loss =  2.25\n",
      "epoch = 2/4, step = 2701/5000, loss =  2.24\n",
      "epoch = 2/4, step = 2801/5000, loss =  2.24\n",
      "epoch = 2/4, step = 2901/5000, loss =  2.24\n",
      "epoch = 2/4, step = 3001/5000, loss =  2.22\n",
      "epoch = 2/4, step = 3101/5000, loss =  2.22\n",
      "epoch = 2/4, step = 3201/5000, loss =  2.20\n",
      "epoch = 2/4, step = 3301/5000, loss =  2.26\n",
      "epoch = 2/4, step = 3401/5000, loss =  2.27\n",
      "epoch = 2/4, step = 3501/5000, loss =  2.23\n",
      "epoch = 2/4, step = 3601/5000, loss =  2.21\n",
      "epoch = 2/4, step = 3701/5000, loss =  2.26\n",
      "epoch = 2/4, step = 3801/5000, loss =  2.24\n",
      "epoch = 2/4, step = 3901/5000, loss =  2.19\n",
      "epoch = 2/4, step = 4001/5000, loss =  2.20\n",
      "epoch = 2/4, step = 4101/5000, loss =  2.25\n",
      "epoch = 2/4, step = 4201/5000, loss =  2.21\n",
      "epoch = 2/4, step = 4301/5000, loss =  2.34\n",
      "epoch = 2/4, step = 4401/5000, loss =  2.21\n",
      "epoch = 2/4, step = 4501/5000, loss =  2.19\n",
      "epoch = 2/4, step = 4601/5000, loss =  2.20\n",
      "epoch = 2/4, step = 4701/5000, loss =  2.24\n",
      "epoch = 2/4, step = 4801/5000, loss =  2.17\n",
      "epoch = 2/4, step = 4901/5000, loss =  2.17\n",
      "epoch = 3/4, step = 1/5000, loss =  2.23\n",
      "epoch = 3/4, step = 101/5000, loss =  2.31\n",
      "epoch = 3/4, step = 201/5000, loss =  2.04\n",
      "epoch = 3/4, step = 301/5000, loss =  2.21\n",
      "epoch = 3/4, step = 401/5000, loss =  2.20\n",
      "epoch = 3/4, step = 501/5000, loss =  2.04\n",
      "epoch = 3/4, step = 601/5000, loss =  2.21\n",
      "epoch = 3/4, step = 701/5000, loss =  2.06\n",
      "epoch = 3/4, step = 801/5000, loss =  2.12\n",
      "epoch = 3/4, step = 901/5000, loss =  2.19\n",
      "epoch = 3/4, step = 1001/5000, loss =  2.06\n",
      "epoch = 3/4, step = 1101/5000, loss =  2.08\n",
      "epoch = 3/4, step = 1201/5000, loss =  2.03\n",
      "epoch = 3/4, step = 1301/5000, loss =  2.08\n",
      "epoch = 3/4, step = 1401/5000, loss =  2.13\n",
      "epoch = 3/4, step = 1501/5000, loss =  2.04\n",
      "epoch = 3/4, step = 1601/5000, loss =  2.05\n",
      "epoch = 3/4, step = 1701/5000, loss =  1.98\n",
      "epoch = 3/4, step = 1801/5000, loss =  1.98\n",
      "epoch = 3/4, step = 1901/5000, loss =  1.90\n",
      "epoch = 3/4, step = 2001/5000, loss =  1.91\n",
      "epoch = 3/4, step = 2101/5000, loss =  1.91\n",
      "epoch = 3/4, step = 2201/5000, loss =  2.24\n",
      "epoch = 3/4, step = 2301/5000, loss =  1.98\n",
      "epoch = 3/4, step = 2401/5000, loss =  2.00\n",
      "epoch = 3/4, step = 2501/5000, loss =  2.11\n",
      "epoch = 3/4, step = 2601/5000, loss =  2.04\n",
      "epoch = 3/4, step = 2701/5000, loss =  2.07\n",
      "epoch = 3/4, step = 2801/5000, loss =  2.48\n",
      "epoch = 3/4, step = 2901/5000, loss =  2.04\n",
      "epoch = 3/4, step = 3001/5000, loss =  2.06\n",
      "epoch = 3/4, step = 3101/5000, loss =  2.08\n",
      "epoch = 3/4, step = 3201/5000, loss =  1.96\n",
      "epoch = 3/4, step = 3301/5000, loss =  2.19\n",
      "epoch = 3/4, step = 3401/5000, loss =  2.44\n",
      "epoch = 3/4, step = 3501/5000, loss =  2.08\n",
      "epoch = 3/4, step = 3601/5000, loss =  1.87\n",
      "epoch = 3/4, step = 3701/5000, loss =  1.67\n",
      "epoch = 3/4, step = 3801/5000, loss =  1.87\n",
      "epoch = 3/4, step = 3901/5000, loss =  2.42\n",
      "epoch = 3/4, step = 4001/5000, loss =  1.72\n",
      "epoch = 3/4, step = 4101/5000, loss =  1.96\n",
      "epoch = 3/4, step = 4201/5000, loss =  2.14\n",
      "epoch = 3/4, step = 4301/5000, loss =  2.19\n",
      "epoch = 3/4, step = 4401/5000, loss =  1.75\n",
      "epoch = 3/4, step = 4501/5000, loss =  1.80\n",
      "epoch = 3/4, step = 4601/5000, loss =  2.16\n",
      "epoch = 3/4, step = 4701/5000, loss =  1.73\n",
      "epoch = 3/4, step = 4801/5000, loss =  2.23\n",
      "epoch = 3/4, step = 4901/5000, loss =  1.86\n",
      "epoch = 4/4, step = 1/5000, loss =  2.09\n",
      "epoch = 4/4, step = 101/5000, loss =  1.62\n",
      "epoch = 4/4, step = 201/5000, loss =  1.70\n",
      "epoch = 4/4, step = 301/5000, loss =  1.78\n",
      "epoch = 4/4, step = 401/5000, loss =  1.81\n",
      "epoch = 4/4, step = 501/5000, loss =  1.83\n",
      "epoch = 4/4, step = 601/5000, loss =  1.98\n",
      "epoch = 4/4, step = 701/5000, loss =  1.81\n",
      "epoch = 4/4, step = 801/5000, loss =  2.21\n",
      "epoch = 4/4, step = 901/5000, loss =  1.87\n",
      "epoch = 4/4, step = 1001/5000, loss =  2.16\n",
      "epoch = 4/4, step = 1101/5000, loss =  1.81\n",
      "epoch = 4/4, step = 1201/5000, loss =  2.17\n",
      "epoch = 4/4, step = 1301/5000, loss =  2.14\n",
      "epoch = 4/4, step = 1401/5000, loss =  1.84\n",
      "epoch = 4/4, step = 1501/5000, loss =  1.80\n",
      "epoch = 4/4, step = 1601/5000, loss =  2.02\n",
      "epoch = 4/4, step = 1701/5000, loss =  1.75\n",
      "epoch = 4/4, step = 1801/5000, loss =  1.59\n",
      "epoch = 4/4, step = 1901/5000, loss =  1.57\n",
      "epoch = 4/4, step = 2001/5000, loss =  1.78\n",
      "epoch = 4/4, step = 2101/5000, loss =  1.53\n",
      "epoch = 4/4, step = 2201/5000, loss =  2.11\n",
      "epoch = 4/4, step = 2301/5000, loss =  2.15\n",
      "epoch = 4/4, step = 2401/5000, loss =  1.56\n",
      "epoch = 4/4, step = 2501/5000, loss =  1.91\n",
      "epoch = 4/4, step = 2601/5000, loss =  1.80\n",
      "epoch = 4/4, step = 2701/5000, loss =  1.93\n",
      "epoch = 4/4, step = 2801/5000, loss =  1.76\n",
      "epoch = 4/4, step = 2901/5000, loss =  2.30\n",
      "epoch = 4/4, step = 3001/5000, loss =  1.95\n",
      "epoch = 4/4, step = 3101/5000, loss =  1.87\n",
      "epoch = 4/4, step = 3201/5000, loss =  1.61\n",
      "epoch = 4/4, step = 3301/5000, loss =  1.62\n",
      "epoch = 4/4, step = 3401/5000, loss =  1.95\n",
      "epoch = 4/4, step = 3501/5000, loss =  1.97\n",
      "epoch = 4/4, step = 3601/5000, loss =  2.04\n",
      "epoch = 4/4, step = 3701/5000, loss =  1.81\n",
      "epoch = 4/4, step = 3801/5000, loss =  1.16\n",
      "epoch = 4/4, step = 3901/5000, loss =  1.86\n",
      "epoch = 4/4, step = 4001/5000, loss =  2.02\n",
      "epoch = 4/4, step = 4101/5000, loss =  2.09\n",
      "epoch = 4/4, step = 4201/5000, loss =  2.07\n",
      "epoch = 4/4, step = 4301/5000, loss =  1.60\n",
      "epoch = 4/4, step = 4401/5000, loss =  2.06\n",
      "epoch = 4/4, step = 4501/5000, loss =  1.81\n",
      "epoch = 4/4, step = 4601/5000, loss =  1.83\n",
      "epoch = 4/4, step = 4701/5000, loss =  1.67\n",
      "epoch = 4/4, step = 4801/5000, loss =  1.50\n",
      "epoch = 4/4, step = 4901/5000, loss =  1.81\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        # forward pass :- put input in model and calculate loss\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels)\n",
    "        \n",
    "        #backward pass :-\n",
    "        optimizer.zero_grad()       #learn these three steps in backpass - zerograd, backward se gradients calc, step se weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i%100 == 0) :\n",
    "            print(f'epoch = {epoch+1}/{num_epochs}, step = {i+1}/{total_steps}, loss = {loss : .2f}')\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35.2100)\n"
     ]
    }
   ],
   "source": [
    "# accuracy kya hai model ki\n",
    "with torch.no_grad():\n",
    "    correct = 0;\n",
    "    total = 0;\n",
    "    for (images,labels) in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        \n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        \n",
    "    acc = (correct/total)*100\n",
    "    print(acc) \n",
    "        \n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy is low due to less number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "\n",
    "torch.save(model.state_dict(),\"Cifar_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load model \n",
    "\n",
    "model.load_state_dict(torch.load(\"Cifar_model.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c97f6a8d471a84aac9f6a8c201c73e6a1f18dc0ca9e3e10111ba9dd8335f84c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
